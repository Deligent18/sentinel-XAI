name: Sentinel XAI - CI/CD Pipeline\non:\n  push:\n    branches:\n      - main\n      - develop\n  pull_request:\n    branches:\n      - main\n  workflow_dispatch:\n\nenv:\n  PYTHON_VERSION: '3.11'\n  DB_HOST: localhost\n  DB_USER: root\n  DB_PASSWORD: root123\n  DB_NAME: xai_student_risk_db\n\njobs:\n  # Database Setup\n  setup-database:\n    runs-on: ubuntu-latest\n    services:\n      mysql:\n        image: mysql:8.0\n        env:\n          MYSQL_ROOT_PASSWORD: root123\n          MYSQL_DATABASE: xai_student_risk_db\n        options: >-\n          --health-cmd="mysqladmin ping"\n          --health-interval=10s\n          --health-timeout=5s\n          --health-retries=3\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Import SQL schema\n        run: |\n          mysql -h 127.0.0.1 -u root -proot123 < xai_student_risk_schema.sql\n      \n      - name: Verify database tables\n        run: |\n          mysql -h 127.0.0.1 -u root -proot123 xai_student_risk_db -e "SHOW TABLES;"\n\n  # Generate Synthetic Data\n  generate-data:\n    needs: setup-database\n    runs-on: ubuntu-latest\n    services:\n      mysql:\n        image: mysql:8.0\n        env:\n          MYSQL_ROOT_PASSWORD: root123\n          MYSQL_DATABASE: xai_student_risk_db\n        options: >-\n          --health-cmd="mysqladmin ping"\n          --health-interval=10s\n          --health-timeout=5s\n          --health-retries=3\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n      \n      - name: Install database schema\n        run: |\n          mysql -h 127.0.0.1 -u root -proot123 < xai_student_risk_schema.sql\n      \n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pandas numpy scikit-learn imbalanced-learn sqlalchemy pymysql matplotlib seaborn joblib python-dotenv\n      \n      - name: Generate synthetic data\n        run: |\n          python generate_synthetic_data.py\n        env:\n          DB_HOST: 127.0.0.1\n          DB_USER: root\n          DB_PASSWORD: root123\n          DB_NAME: xai_student_risk_db\n      \n      - name: Verify data generation\n        run: |\n          mysql -h 127.0.0.1 -u root -proot123 xai_student_risk_db -e "SELECT 'Student' AS tbl, COUNT(*) AS cnt FROM Student UNION ALL SELECT 'Academic_Record', COUNT(*) FROM Academic_Record UNION ALL SELECT 'Campus_Behaviour', COUNT(*) FROM Campus_Behaviour UNION ALL SELECT 'LMS_Activity', COUNT(*) FROM LMS_Activity UNION ALL SELECT 'Risk_Prediction', COUNT(*) FROM Risk_Prediction;"\n      \n      - name: Upload data artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: database-state\n          path: .env\n          retention-days: 1\n\n  # Data Preprocessing\n  preprocess-data:\n    needs: generate-data\n    runs-on: ubuntu-latest\n    services:\n      mysql:\n        image: mysql:8.0\n        env:\n          MYSQL_ROOT_PASSWORD: root123\n          MYSQL_DATABASE: xai_student_risk_db\n        options: >-\n          --health-cmd="mysqladmin ping"\n          --health-interval=10s\n          --health-timeout=5s\n          --health-retries=3\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n      \n      - name: Install database schema\n        run: |\n          mysql -h 127.0.0.1 -u root -proot123 < xai_student_risk_schema.sql\n      \n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pandas numpy scikit-learn imbalanced-learn sqlalchemy pymysql matplotlib seaborn joblib python-dotenv xgboost shap\n      \n      - name: Create required directories\n        run: |\n          mkdir -p data/processed models plots reports\n      \n      - name: Generate synthetic data for pipeline\n        run: |\n          python generate_synthetic_data.py\n        env:\n          DB_HOST: 127.0.0.1\n          DB_USER: root\n          DB_PASSWORD: root123\n          DB_NAME: xai_student_risk_db\n      \n      - name: Run data preprocessing\n        run: |\n          python data_preprocessing.py 2>&1 | tee reports/preprocessing_run.log\n        env:\n          DB_HOST: 127.0.0.1\n          DB_USER: root\n          DB_PASSWORD: root123\n          DB_NAME: xai_student_risk_db\n      \n      - name: Verify output files\n        run: |\n          echo "=== Processed Data ===" && ls -lh data/processed/ && echo "=== Models ===" && ls -lh models/ && echo "=== Plots ===" && ls -lh plots/ && echo "=== Reports ===" && ls -lh reports/\n      \n      - name: Verify data splits\n        run: |\n          python -c \"\n          import pandas as pd\n          import os\n          X_train = pd.read_csv('data/processed/X_train.csv')\n          X_val = pd.read_csv('data/processed/X_val.csv')\n          X_test = pd.read_csv('data/processed/X_test.csv')\n          y_train = pd.read_csv('data/processed/y_train.csv')\n          print(f'Training set: {X_train.shape}')\n          print(f'Validation set: {X_val.shape}')\n          print(f'Test set: {X_test.shape}')\n          print(f'Features: {X_train.shape[1]}')\n          print('\nClass distribution (train):')\n          print(y_train.value_counts())\n          \"\n      \n      - name: Upload processed data artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: processed-data\n          path: |\n            data/processed/\n            models/\n            plots/\n            reports/\n          retention-days: 5\n\n  # Quality Checks & Testing\n  quality-checks:\n    needs: preprocess-data\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n      \n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pandas numpy scikit-learn pylint flake8\n      \n      - name: Run code linting\n        run: |\n          pylint data_preprocessing.py --fail-under=7.0 || true\n          flake8 data_preprocessing.py --max-line-length=120 --count || true\n      \n      - name: Python syntax check\n        run: |\n          python -m py_compile data_preprocessing.py generate_synthetic_data.py\n\n  # Build Frontend\n  build-frontend:\n    runs-on: ubuntu-latest\n    if: always()\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Check if frontend exists\n        id: check-frontend\n        run: |\n          if [ -d "frontend" ] && [ -f "frontend/package.json" ]; then\n            echo "exists=true" >> $GITHUB_OUTPUT\n          else\n            echo "exists=false" >> $GITHUB_OUTPUT\n          fi\n      \n      - name: Setup Node.js\n        if: steps.check-frontend.outputs.exists == 'true'\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n          cache: 'npm'\n          cache-dependency-path: frontend/package-lock.json\n      \n      - name: Install frontend dependencies\n        if: steps.check-frontend.outputs.exists == 'true'\n        run: cd frontend && npm ci\n      \n      - name: Build frontend\n        if: steps.check-frontend.outputs.exists == 'true'\n        run: cd frontend && npm run build || echo "Frontend build skipped"\n      \n      - name: Upload frontend artifacts\n        if: steps.check-frontend.outputs.exists == 'true'\n        uses: actions/upload-artifact@v4\n        with:\n          name: frontend-build\n          path: frontend/build/\n          retention-days: 5\n\n  # Build Backend\n  build-backend:\n    runs-on: ubuntu-latest\n    if: always()\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Check if backend exists\n        id: check-backend\n        run: |\n          if [ -d "backend" ] && [ -f "backend/requirements.txt" ]; then\n            echo "exists=true" >> $GITHUB_OUTPUT\n          else\n            echo "exists=false" >> $GITHUB_OUTPUT\n          fi\n      \n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n      \n      - name: Install backend dependencies\n        if: steps.check-backend.outputs.exists == 'true'\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r backend/requirements.txt\n      \n      - name: Run backend tests\n        if: steps.check-backend.outputs.exists == 'true'\n        run: |\n          cd backend && python -m pytest tests/ -v --tb=short || echo "No tests found"\n        continue-on-error: true\n\n  # Deploy to GitHub Pages\n  deploy-frontend:\n    needs: build-frontend\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main' && github.event_name == 'push'\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Check if frontend exists\n        id: check-frontend\n        run: |\n          if [ -f "frontend/package.json" ]; then\n            echo "exists=true" >> $GITHUB_OUTPUT\n          else\n            echo "exists=false" >> $GITHUB_OUTPUT\n          fi\n      \n      - name: Download frontend artifacts\n        if: steps.check-frontend.outputs.exists == 'true'\n        uses: actions/download-artifact@v4\n        with:\n          name: frontend-build\n          path: frontend/build/\n      \n      - name: Deploy to GitHub Pages\n        if: steps.check-frontend.outputs.exists == 'true'\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: \${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./frontend/build\n\n  # Final Report\n  summary:\n    needs: [preprocess-data, quality-checks, build-frontend, build-backend]\n    runs-on: ubuntu-latest\n    if: always()\n    steps:\n      - name: Pipeline Summary\n        run: |\n          echo "============================================"\n          echo "  Sentinel XAI - CI/CD Pipeline Summary"\n          echo "============================================"\n          echo "✅ Database Setup: ${{ needs.preprocess-data.result }}"\n          echo "✅ Data Preprocessing: ${{ needs.preprocess-data.result }}"\n          echo "✅ Quality Checks: ${{ needs.quality-checks.result }}"\n          echo "✅ Frontend Build: ${{ needs.build-frontend.result }}"\n          echo "✅ Backend Build: ${{ needs.build-backend.result }}"\n          echo "============================================"\n          echo "Pipeline Status: ${{ job.status }}"\n          echo "============================================"\n